{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метрики и валидация\n",
    "\n",
    "Датасеты скачивать по ссылке: https://disk.yandex.ru/d/cwL3Ka4ECyQwpw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import (\n",
    "    ElasticNet,\n",
    "    ElasticNetCV,\n",
    "    Lasso,\n",
    "    LassoCV,\n",
    "    LinearRegression,\n",
    "    LogisticRegression,\n",
    "    Ridge,\n",
    "    RidgeCV,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    RocCurveDisplay,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_squared_error,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    r2_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    RepeatedKFold,\n",
    "    cross_val_predict,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from houses_data_engineering import prepare_houses_data\n",
    "from mushrooms_data_engineering import prepare_mushrooms_data\n",
    "from wdbc_data_engineering import prepare_wdbc_data\n",
    "\n",
    "\n",
    "SEED = 314159\n",
    "TRAIN_TEST_SPLIT = 0.80\n",
    "\n",
    "\n",
    "with open(\"../config.yaml\", \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные\n",
    "\n",
    "Опустим этап инженерии данных, все три датасеты уже были рассмотрены на предыдущих занятиях. Все необходимые трансформации данных вынесены в отдельные .py модули."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### House prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_houses_init = pd.read_csv(cfg[\"house_prices\"][\"train_dataset\"])\n",
    "y_houses = df_houses_init[\"SalePrice\"]\n",
    "df_houses_init.drop(columns=[\"SalePrice\", \"Id\"], inplace=True)\n",
    "\n",
    "df_houses_train_init, df_houses_test, y_houses_train, y_houses_test = train_test_split(\n",
    "    df_houses_init, y_houses, test_size=1 - TRAIN_TEST_SPLIT, random_state=SEED\n",
    ")\n",
    "\n",
    "df_houses_train, df_houses_test, y_houses_train, y_houses_test = prepare_houses_data(\n",
    "    df_train=df_houses_train_init,\n",
    "    df_test=df_houses_test,\n",
    "    y_train=y_houses_train,\n",
    "    y_test=y_houses_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WDBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wdbc = pd.read_csv(cfg[\"wdbc\"])\n",
    "\n",
    "y_wdbc = df_wdbc[[\"diagnosis\"]].replace({\"B\": 0, \"M\": 1})\n",
    "df_wdbc.drop(columns=[\"id\", \"Unnamed: 32\", \"diagnosis\"], inplace=True)\n",
    "\n",
    "df_wdbc_train, df_wdbc_test, y_wdbc_train, y_wdbc_test = train_test_split(\n",
    "    df_wdbc, y_wdbc, test_size=1 - TRAIN_TEST_SPLIT, random_state=SEED\n",
    ")\n",
    "\n",
    "df_wdbc_train, df_wdbc_test = prepare_wdbc_data(\n",
    "    df_train=df_wdbc_train, df_test=df_wdbc_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mushrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mushrooms = pd.read_csv(cfg[\"mushrooms\"])\n",
    "\n",
    "y_mushrooms = df_mushrooms[[\"class\"]].replace({\"e\": 0, \"p\": 1})\n",
    "df_mushrooms.drop(columns=[\"class\"], inplace=True)\n",
    "\n",
    "(\n",
    "    df_mushrooms_train,\n",
    "    df_mushrooms_test,\n",
    "    y_mushrooms_train,\n",
    "    y_mushrooms_test,\n",
    ") = train_test_split(\n",
    "    df_mushrooms, y_mushrooms, test_size=1 - TRAIN_TEST_SPLIT, random_state=SEED\n",
    ")\n",
    "\n",
    "df_mushrooms_train, df_mushrooms_test = prepare_mushrooms_data(\n",
    "    df_train=df_mushrooms_train, df_test=df_mushrooms_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Моделирование и анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала рассмотрим API sklearn для проведения кросс-валидации.\n",
    "\n",
    "Гайд по схемам кросс-валидации, реализованных в sklearn: https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "\n",
    "API: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection\n",
    "\n",
    "Основные функции для проведения кросс-валидации: `cross_validate`, `cross_val_predict` и `cross_val_score`.\n",
    "\n",
    "Важно отметить аргумент `cv`: это может быть как целое количество фолдов (по сути _K_), один из рассмотренных CV-splitter'ов, так и кастомный итератор, который возвращает индексы для тренировочной и тестовой части разбиения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_cv_res = cross_validate(\n",
    "    estimator=LinearRegression(),\n",
    "    X=df_houses_train,\n",
    "    y=y_houses_train,\n",
    "    scoring=[\"r2\", \"neg_mean_absolute_percentage_error\"],\n",
    "    cv=RepeatedKFold(n_splits=5, n_repeats=3),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cross_validate` возвращает не только значения метрик (можно передавать целый список), но и время, затраченное на обучение и вычисление метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_cv_pred_res = cross_val_predict(\n",
    "    estimator=LinearRegression(),\n",
    "    X=df_houses_train,\n",
    "    y=y_houses_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как уже было отмечено, для k-fold CV каждое наблюдение попадает в отложенную часть лишь раз. `cross_val_predict` возвращает эти предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_cv_pred_res.shape, linreg_cv_pred_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_cv_score_res = cross_val_score(\n",
    "    estimator=LinearRegression(),\n",
    "    X=df_houses_train,\n",
    "    y=y_houses_train,\n",
    "    cv=5,\n",
    "    scoring=\"r2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cross_val_score` возвращает значения (лишь одной) метрики на "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_cv_score_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что касается применения кросс-валидации для подбора гиперпараметров моделей, то в sklearn реализованы \n",
    "- `GridSearchCV` -- все наборы из декартового произведения значений для каждого параметра.\n",
    "- `ParameterGrid` -- задание набора параметров.\n",
    "- `RandomSearchCV` -- сэмплирование параметров с учетом ограничения на количество вариантов.\n",
    "\n",
    "Пример: \n",
    "```python\n",
    "from scipy.stats import uniform\n",
    "distributions = dict(C=uniform(loc=0, scale=4), penalty=['l2', 'l1'])\n",
    "```\n",
    "\n",
    "`RandomSearchCV` практически всегда предпочтительнее `GridSearchCV`. (привести пример с квадратом)\n",
    "\n",
    "За более сложными способами поиска гиперпараметров вроде байесовской оптимизации придется идти в другие библиотеки: hyperopt, optuna, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_gs_cv = GridSearchCV(\n",
    "    estimator=Lasso(random_state=SEED),\n",
    "    param_grid={\"alpha\": [0.001, 0.01, 0.1, 1.0, 2.0, 5.0, 10.0]},\n",
    "    n_jobs=4,\n",
    "    scoring=\"r2\",\n",
    ")\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    lasso_gs_cv.fit(df_houses_train, y_houses_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_gs_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_gs_cv.best_params_, lasso_gs_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В sklearn большинство линейных моделей имеют CV-версии, которые по своей сути являются синтаксическим сахаром для запуска `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "ridge_001 = Ridge(alpha=0.01, random_state=SEED)\n",
    "lasso_1 = Lasso(alpha=1.0, random_state=SEED)\n",
    "elastic_net_1_1 = ElasticNet(alpha=1.0, l1_ratio=1.0, random_state=SEED)\n",
    "\n",
    "# те же модели, но со встроенной возможностью проведения кросс-валидации\n",
    "lasso_cv = LassoCV(cv=RepeatedKFold(n_splits=5, n_repeats=3), random_state=SEED)\n",
    "ridge_cv = RidgeCV(cv=RepeatedKFold(n_splits=5, n_repeats=3))\n",
    "elastic_net_cv = ElasticNetCV(\n",
    "    cv=RepeatedKFold(n_splits=5, n_repeats=3), random_state=SEED, max_iter=10000, \n",
    ")\n",
    "# добавить после первого запуска l1_ratio=1.0,  alphas=[0.01, 0.1, 1.0]\n",
    "\n",
    "models = dict(\n",
    "    zip(\n",
    "        [\n",
    "            \"linreg\",\n",
    "            \"ridge_001\",\n",
    "            \"ridge_cv\",\n",
    "            \"lasso_1\",\n",
    "            \"lasso_cv\",\n",
    "            \"elastic_net_1_1\",\n",
    "            \"elastic_net_cv\",\n",
    "        ],\n",
    "        [\n",
    "            linreg,\n",
    "            ridge_001,\n",
    "            ridge_cv,\n",
    "            lasso_1,\n",
    "            lasso_cv,\n",
    "            elastic_net_1_1,\n",
    "            elastic_net_cv,\n",
    "        ],\n",
    "    )\n",
    ")\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    for model in models.values():\n",
    "        model.fit(df_houses_train, y_houses_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_houses_preds = {}\n",
    "for model_name, model in models.items():\n",
    "    y_houses_preds[model_name] = model.predict(df_houses_test)\n",
    "\n",
    "data = []\n",
    "for model_name, y_pred in y_houses_preds.items():\n",
    "    data.append(\n",
    "        [\n",
    "            model_name,\n",
    "            np.sqrt(mean_squared_error(y_true=y_houses_test, y_pred=y_pred)),\n",
    "            mean_absolute_error(y_true=y_houses_test, y_pred=y_pred),\n",
    "            r2_score(y_true=y_houses_test, y_pred=y_pred),\n",
    "            mean_absolute_percentage_error(y_true=y_houses_test, y_pred=y_pred),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "df_res = pd.DataFrame(data, columns=[\"model_name\", \"RMSE\", \"MAE\", \"R2\", \"MAPE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.sort_values(by=\"R2\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WDBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_wdbc_cv = RandomizedSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_distributions={\n",
    "        \"n_neighbors\": [1, 3, 5, 7, 10, 15, 20, 25, 50],\n",
    "        \"metric\": [\"euclidean\"],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "    },\n",
    "    n_jobs=4,\n",
    "    random_state=SEED,\n",
    "    scoring=\"f1\",\n",
    "    error_score=\"raise\",\n",
    ")\n",
    "knn_wdbc_cv.fit(X=df_wdbc_train.values, y=y_wdbc_train.values.reshape(-1))\n",
    "\n",
    "knn_wdbc_cv.best_params_, knn_wdbc_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"kNN:\",\n",
    "    f1_score(y_true=y_wdbc_test, y_pred=knn_wdbc_cv.predict(df_wdbc_test.values))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнения набор, который использовался на прошлом занятии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_wdbc = KNeighborsClassifier(\n",
    "    n_neighbors=5, metric=\"euclidean\", algorithm=\"brute\", weights=\"uniform\"\n",
    ")\n",
    "knn_wdbc.fit(X=df_wdbc_train.values, y=y_wdbc_train.values.reshape(-1))\n",
    "y_wdbc_knn_pred = knn_wdbc.predict(X=df_wdbc_test.values)\n",
    "print(\"kNN:\", f1_score(y_true=y_wdbc_test, y_pred=y_wdbc_knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_wdbc_cv = RandomizedSearchCV(\n",
    "    estimator=LogisticRegression(random_state=SEED),\n",
    "    param_distributions={\n",
    "        \"penalty\": [\"elasticnet\"],\n",
    "        \"C\": [0.001, 0.01, 0.1, 1.0, 2.0, 5.0, 10.0],\n",
    "        \"l1_ratio\": [0.0, 0.001, 0.01, 0.1, 1.0],\n",
    "        \"solver\": [\"saga\"],\n",
    "    },\n",
    "    n_jobs=4,\n",
    "    random_state=SEED,\n",
    "    scoring=\"f1\",\n",
    "    error_score=\"raise\",\n",
    ")\n",
    "logreg_wdbc_cv.fit(X=df_wdbc_train.values, y=y_wdbc_train.values.reshape(-1))\n",
    "\n",
    "logreg_wdbc_cv.best_params_, logreg_wdbc_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"logreg:\",\n",
    "    f1_score(y_true=y_wdbc_test, y_pred=logreg_wdbc_cv.predict(df_wdbc_test.values))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_wdbc = LogisticRegression(\n",
    "    C=1.0, penalty=\"elasticnet\", l1_ratio=0.1, solver=\"saga\"\n",
    ")\n",
    "logreg_wdbc.fit(X=df_wdbc_train, y=y_wdbc_train.values.reshape(-1))\n",
    "\n",
    "# AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
    "y_wdbc_logreg_pred = logreg_wdbc.predict(df_wdbc_test)\n",
    "\n",
    "print(\"logreg:\", f1_score(y_true=y_wdbc_test, y_pred=y_wdbc_logreg_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mushrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_mushrooms_cv = RandomizedSearchCV(\n",
    "    estimator=KNeighborsClassifier(),\n",
    "    param_distributions={\n",
    "        \"n_neighbors\": [1, 3, 5, 7, 10, 15, 20, 25, 50],\n",
    "        \"metric\": [\"euclidean\"],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "    },\n",
    "    n_jobs=4,\n",
    "    random_state=SEED,\n",
    "    scoring=\"f1\",\n",
    "    error_score=\"raise\",\n",
    ")\n",
    "knn_mushrooms_cv.fit(\n",
    "    X=df_mushrooms_train.values, y=y_mushrooms_train.values.reshape(-1)\n",
    ")\n",
    "\n",
    "knn_mushrooms_cv.best_params_, knn_mushrooms_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"kNN:\",\n",
    "    f1_score(\n",
    "        y_true=y_mushrooms_test,\n",
    "        y_pred=knn_mushrooms_cv.predict(X=df_mushrooms_test.values),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_mushrooms = KNeighborsClassifier(\n",
    "    n_neighbors=5, metric=\"cosine\", algorithm=\"brute\", weights=\"uniform\",\n",
    ")\n",
    "knn_mushrooms.fit(X=df_mushrooms_train, y=y_mushrooms_train.values.reshape(-1))\n",
    "y_mushrooms_knn_pred = knn_mushrooms.predict(X=df_mushrooms_test.values)\n",
    "print(\"kNN:\", f1_score(y_true=y_mushrooms_test, y_pred=y_mushrooms_knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_mushrooms_cv = RandomizedSearchCV(\n",
    "    estimator=LogisticRegression(random_state=SEED),\n",
    "    param_distributions={\n",
    "        \"penalty\": [\"elasticnet\"],\n",
    "        \"C\": [0.001, 0.01, 0.1, 1.0, 2.0, 5.0, 10.0],\n",
    "        \"l1_ratio\": [0.0, 0.001, 0.01, 0.1, 1.0],\n",
    "        \"solver\": [\"saga\"],\n",
    "    },\n",
    "    n_jobs=4,\n",
    "    random_state=SEED,\n",
    "    scoring=\"f1\",\n",
    "    error_score=\"raise\",\n",
    ")\n",
    "logreg_mushrooms_cv.fit(\n",
    "    X=df_mushrooms_train.values, y=y_mushrooms_train.values.reshape(-1)\n",
    ")\n",
    "\n",
    "logreg_mushrooms_cv.best_params_, logreg_mushrooms_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"logreg:\",\n",
    "    f1_score(\n",
    "        y_true=y_mushrooms_test,\n",
    "        y_pred=logreg_mushrooms_cv.predict(df_mushrooms_test.values),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_mushrooms = LogisticRegression(\n",
    "    C=1.0, penalty=\"elasticnet\", l1_ratio=0.1, solver=\"saga\", random_state=SEED\n",
    ")\n",
    "logreg_mushrooms.fit(X=df_mushrooms_train, y=y_mushrooms_train.values.reshape(-1))\n",
    "\n",
    "# AttributeError: 'Flags' object has no attribute 'c_contiguous'\n",
    "y_mushrooms_pred = logreg_mushrooms.predict(X=df_mushrooms_test)\n",
    "print(\"logreg:\", f1_score(y_true=y_mushrooms_test, y_pred=y_mushrooms_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метрики классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_logreg_wdbc_pred_probas = logreg_wdbc_cv.predict_proba(df_wdbc_test.values)\n",
    "y_logreg_wdbc_pred = logreg_wdbc_cv.predict(df_wdbc_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_true=y_wdbc_test, y_pred=y_logreg_wdbc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_wdbc_test, y_pred=y_logreg_wdbc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy:\", accuracy_score(y_true=y_wdbc_test, y_pred=y_logreg_wdbc_pred))\n",
    "print(\n",
    "    \"balanced accuracy:\",\n",
    "    balanced_accuracy_score(y_true=y_wdbc_test, y_pred=y_logreg_wdbc_pred),\n",
    ")\n",
    "print(\"precision:\", precision_score(y_true=y_wdbc_test, y_pred=y_logreg_wdbc_pred))\n",
    "print(\"recall:\", balanced_accuracy_score(y_true=y_wdbc_test, y_pred=y_logreg_wdbc_pred))\n",
    "print(\"f1:\", f1_score(y_true=y_wdbc_test, y_pred=y_logreg_wdbc_pred))\n",
    "print(\n",
    "    \"roc auc:\",\n",
    "    roc_auc_score(y_true=y_wdbc_test, y_score=y_logreg_wdbc_pred_probas[:, 1]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_predictions(\n",
    "    y_wdbc_test,\n",
    "    y_logreg_wdbc_pred_probas[:, 1],\n",
    "    color=\"darkorange\",\n",
    "    plot_chance_level=True,\n",
    ")\n",
    "plt.axis(\"square\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b3714695f2307aafe7da52bf6e53e38bc5469a267534973be7d21c816457eaf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
